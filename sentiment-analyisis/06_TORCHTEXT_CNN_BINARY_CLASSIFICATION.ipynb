{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Torchtext Covulutinal Neural Nets (CNN) (Conv1d)\n",
        "\n",
        "In this notebook we are going to create a modl that will do simple binary classification using the `IMDB` dataset. From the previous notebooks we have been looking on how we can load our own dataset from files. In this notebookwe are going to use the `torchtext.dataset` to load available datasets from `torchtext`. The text classification datasets are listed in the [docs](https://pytorch.org/text/stable/datasets.html#imdb).\n",
        "\n",
        "> This notebook will look similar to the previous one we are just going to change few things.\n",
        "\n",
        "\n",
        "###  Installation of Packages\n",
        "\n",
        "In the following code cell we are going to install the packages that we are going to use in this notebook which are `helperfns`, `torchdata` and `emoji`. The `emoji` package allows us to get emoji text and we will use it later on in this notebook. The `helperfns` package allows us to get some machine learning helper function which we are also going to use in this notebook as well."
      ],
      "metadata": {
        "id": "1aKlPSIJdlYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install helperfns -q"
      ],
      "metadata": {
        "id": "n0KCek_jjbQw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07807784-0937-499d-fcf1-ca59e1104d37"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmAJF6ISffkR",
        "outputId": "f4f225bb-a372-44a2-a007-839d69b52b36"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20 kB 37.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 30 kB 45.8 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 40 kB 37.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 51 kB 41.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 61 kB 45.6 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 71 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 81 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 92 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 102 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 112 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 122 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 133 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 143 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 153 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 163 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 174 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 184 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 194 kB 34.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 197 kB 34.6 MB/s \n",
            "\u001b[?25h  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchdata -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIR99rYBD8g0",
        "outputId": "4188adcc-7845-4fdf-8a8c-0556ac58589d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 4.4 MB 25.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 66.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 63.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports \n",
        "\n",
        "In the following code cell we are going to import all the packages that are going to be used in this notebook."
      ],
      "metadata": {
        "id": "FPLcPXOMfi_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QqwZb0v5rnro",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a11a410-0c77-4d2f-f328-92a47524f5fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0.13.1', '1.12.1+cu113')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import time\n",
        "import emoji\n",
        "import torch\n",
        "import os\n",
        "import random\n",
        "import torchtext\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive\n",
        "from torch import nn\n",
        "from torchtext import data\n",
        "from collections import Counter\n",
        "from torchtext import vocab\n",
        "from helperfns import tables, visualization, utils\n",
        "\n",
        "from torchtext.datasets import IMDB\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "torchtext.__version__, torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Device\n",
        "In the following code cell we are going to create a device variable and utilize the `cuda` GPU if available in this notebook."
      ],
      "metadata": {
        "id": "C4G6h3V2hIkH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCwjrdaMr3S0",
        "outputId": "3324914b-9d27-4dae-c3bd-ffd534f3a170"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Seed\n",
        "\n",
        "In the following  code cell we are going to define the seed for reproducivity in this notebook."
      ],
      "metadata": {
        "id": "J7sJbYQNhaG-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "x5zxG5Nyr2SI"
      },
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deteministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading IMDB dataset\n",
        "In the following code cell we are going to load the `IMDB` dataset."
      ],
      "metadata": {
        "id": "ms3dQsYPhlzJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "74qQGlLor5sb"
      },
      "outputs": [],
      "source": [
        "train_iter, test_iter = IMDB(root=\".data\", split=('train', \"test\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting text and labels\n",
        "\n",
        "In the following code cell we are then going to get the features and labels for our sets."
      ],
      "metadata": {
        "id": "dUuNTiWRF--D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = []\n",
        "train_labels = []\n",
        "\n",
        "for (labels, line) in train_iter:\n",
        "  train_text.append(line)\n",
        "  train_labels.append(labels)\n",
        "\n",
        "test_text = []\n",
        "test_labels = []\n",
        "\n",
        "for (labels, texts) in test_iter:\n",
        "  test_text.append(texts)\n",
        "  test_labels.append(labels)"
      ],
      "metadata": {
        "id": "PJ5HZXj8Euiw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(test_text) == len(test_labels)\n",
        "assert len(train_text) == len(train_labels)"
      ],
      "metadata": {
        "id": "XmOrVIl1hEyz"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking examples."
      ],
      "metadata": {
        "id": "Pz7S2a9RibuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_text[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-U1MjcK8hfy9",
        "outputId": "1f389c65-bed2-4499-e25e-c074c302e162"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Zentropa has much in common with The Third Man, another noir-like film set among the rubble of postwar Europe. Like TTM, there is much inventive camera work. There is an innocent American who gets emotionally involved with a woman he doesn\\'t really understand, and whose naivety is all the more striking in contrast with the natives.<br /><br />But I\\'d have to say that The Third Man has a more well-crafted storyline. Zentropa is a bit disjointed in this respect. Perhaps this is intentional: it is presented as a dream/nightmare, and making it too coherent would spoil the effect. <br /><br />This movie is unrelentingly grim--\"noir\" in more than one sense; one never sees the sun shine. Grim, but intriguing, and frightening.',\n",
              " \"Zentropa is the most original movie I've seen in years. If you like unique thrillers that are influenced by film noir, then this is just the right cure for all of those Hollywood summer blockbusters clogging the theaters these days. Von Trier's follow-ups like Breaking the Waves have gotten more acclaim, but this is really his best work. It is flashy without being distracting and offers the perfect combination of suspense and dark humor. It's too bad he decided handheld cameras were the wave of the future. It's hard to say who talked him away from the style he exhibits here, but it's everyone's loss that he went into his heavily theoretical dogma direction instead.\"]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSF67Fc-ijkr",
        "outputId": "e1c5a105-4a12-4592-9839-9e4f25407778"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pos', 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZmIkSqhHimGA",
        "outputId": "5265fe40-4509-45b9-a2a4-c1c67a0c5f44"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Previous reviewer Claudio Carvalho gave a much better recap of the film's plot details than I could. What I recall mostly is that it was just so beautiful, in every sense - emotionally, visually, editorially - just gorgeous.<br /><br />If you like movies that are wonderful to look at, and also have emotional content to which that beauty is relevant, I think you will be glad to have seen this extraordinary and unusual work of art.<br /><br />On a scale of 1 to 10, I'd give it about an 8.75. The only reason I shy away from 9 is that it is a mood piece. If you are in the mood for a really artistic, very romantic film, then it's a 10. I definitely think it's a must-see, but none of us can be in that mood all the time, so, overall, 8.75.\",\n",
              " 'CONTAINS \"SPOILER\" INFORMATION. Watch this director\\'s other film, \"Earth\", at some point. It\\'s a better film, but this one isn\\'t bad just different.<br /><br />A rare feminist point of view from an Indian filmmaker. Tradition, rituals, duty, secrets, and the portrayal of strict sex roles make this an engaging and culturally dynamic film viewing experience. All of the married characters lack the \"fire\" of the marriage bed with their respective spouses. One husband is celibate and commits a form of spiritual \"adultery\" by giving all of his love, honor, time and respect to his religious swami (guru). His wife is lonely and yearns for intimacy and tenderness which she eventually finds with her closeted lesbian sister-in-law who comes to live in their house with her unfaithful husband. This unfaithful husband is openly in love with his Chinese mistress but was forced into marriage with a (unbeknownest to him) lesbian. They only have sex once when his closet lesbian wife loses her virginity.<br /><br />A servant lives in the house and he eventually reveals the secret that the two women are lovers. Another significant character is the elderly matriarch who is unable to speak or care for herself due to a stroke. However, she uses a ringing bell to communicate her needs as well as her displeasure with the family members. She lets them know through her bell or by pounding her fist that she knows exacly what\\'s going on in the house and how much she disapproves.<br /><br />In the end, the truth about everybody comes out and the two female lovers end up running away together. But, not before there is an emotional scene between the swami-addicted husband and his formerly straight wife. Her sari catches on fire and at first we think she is going to die. However, we see the two women united in the very last scene of the movie.<br /><br />The writer/director of this film challenges her culture\\'s traditions, but she shows us individual human beings who are trapped by their culture and gender. We come to really care about the characters and we don\\'t see them as stereotypes. Each on surprises us with their humanity, vulgarity, tenderness, anger, and spirit.']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels[:2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCJHtwxdiqAT",
        "outputId": "7608e03c-045d-46c5-dede-1a4cbfb5c8a5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pos', 'pos']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Counting examples\n",
        "In the following code cell we are going to count how many examples do we have in each set and visualize them in a tabular format."
      ],
      "metadata": {
        "id": "ckAt_RExjDP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns = [\"Set\", \"Example(s)\"]\n",
        "examples = [\n",
        "    ['training', len(train_text)],\n",
        "    ['testing', len(test_text)],\n",
        "    ['total', len(train_text) +  len(test_text)],\n",
        "]\n",
        "tables.tabulate_data(columns, examples, \"Exmples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVM1jGiDkIs4",
        "outputId": "e5f5eeb5-2c33-4be7-e322-0ed6aeac00b4"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------+\n",
            "|        Exmples        |\n",
            "+----------+------------+\n",
            "|   Set    | Example(s) |\n",
            "+----------+------------+\n",
            "| training |      25000 |\n",
            "| testing  |      25000 |\n",
            "| total    |      50000 |\n",
            "+----------+------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Preprocessing\n",
        "In our text processing pipeline we need to do the following step:\n",
        "\n",
        "1. tokenize text \n",
        "- this is the process of converting a sentence or text into senquence of word. For this we are going to use a pre-trained model from `spacy` language model. You can read more about other tokenizers that you can use at [pytorch.org](https://pytorch.org/text/stable/data_utils.html).\n",
        "\n",
        "2. vocabulary\n",
        "* We will to create a vocabulary based on our text. A vocabulary is esentially a word to index mapping that allows us to reference the word with their integer representation, since machine leaning models does not understand words. This vocabulary will be used during model training and also can be used at model inference.\n",
        "\n",
        "\n",
        "#### Tokenizer\n",
        "\n",
        "In the following code cell we are going to geta a tokenier object that will convert a sentence into a sequence of word using the `spacy-en` language model."
      ],
      "metadata": {
        "id": "kvmHM7TglDOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = data.utils.get_tokenizer('spacy', 'en')\n",
        "tokenizer(\"This is a boy.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5QLQUzQnZ2Y",
        "outputId": "28eef4db-5226-4640-ba8a-81181deb65eb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchtext/data/utils.py:106: UserWarning: Spacy model \"en\" could not be loaded, trying \"en_core_web_sm\" instead\n",
            "  f'Spacy model \"{language}\" could not be loaded, trying \"{OLD_MODEL_SHORTCUTS[language]}\" instead'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', 'a', 'boy', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Cleaning\n",
        "In this notebook i will not focus much about text cleaning, but to improve the model accuracy we need to do text cleaning.\n",
        "\n",
        "#### Vocabulary\n",
        "In the following code cell we are going to create a vocabulary object from  `torchtext`. This vocabulary takes in an `ordered_dict` of words to their count. So we are going to use the `Counter` module from collections to generate these counts from our train features.\n",
        "\n",
        "We are going to specify the `min_freq` to `5` meaning that the words that does not appear at least 5 times will be converted to unknown. We are also going to specify the special tokens during creation of the vocabulary object. "
      ],
      "metadata": {
        "id": "O0cvl-Cvnlsj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "cCcXNIhlsWEx"
      },
      "outputs": [],
      "source": [
        "counter = Counter()\n",
        "for line in train_text:\n",
        "    counter.update(tokenizer(line.lower()))\n",
        "vocabulary = vocab.vocab(counter, min_freq=5, specials=('<unk>', '<sos>', '<eos>', '<pad>'))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### STOI - String To Integer\n",
        "This will be a dictionary that contains a string to integer mapping which will be our actual vocabulary. In the following code cell we are going to create object called `stoi` which is essentially a dictionary of word to index mapping."
      ],
      "metadata": {
        "id": "_YO81NcEolqJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "NCnX2lY919mX"
      },
      "outputs": [],
      "source": [
        "stoi = vocabulary.get_stoi()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Pipeline\n",
        "\n",
        "After our text has been tokenized we need a way of converting those words into numbers because machine leaning models understand numbers not words. That's where we the `text_pipeline` function comes over. So this function takes in a sentence and tokenize it then converts each word to a number. Note that the word that does not exists in the vocabulay `stoi` will be habin an unkown (`<unk>`) index."
      ],
      "metadata": {
        "id": "8wONl763pMCz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "jzy2r6TGvnV5"
      },
      "outputs": [],
      "source": [
        "def text_pipeline(x: str):\n",
        "  values = list()\n",
        "  tokens = tokenizer(x.lower()) # convert to lower case.\n",
        "  for token in tokens:\n",
        "    try:\n",
        "      v = stoi[token]\n",
        "    except KeyError as e:\n",
        "      v = stoi['<unk>']\n",
        "    values.append(v)\n",
        "  return values"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Label pipeline\n",
        "\n",
        " We also need to convert these labels into numbers. This is very simple what we need to do is to get all the uniqe labels and then create a `labels_vocab` which is a label to integer representation. Which looks as follows:\n",
        "\n",
        "```\n",
        "{'pos': 1, 'neg': 0}\n",
        "```\n",
        "The `label_pipeline` function will then takes in the label and then returns us an integer representation of that label."
      ],
      "metadata": {
        "id": "GsN_vOuXqGCJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXRyHQpCvu-5",
        "outputId": "2608458d-b58c-49ec-d28f-7c0f022a2511"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'pos': 1, 'neg': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "labels_dict = {'pos': 1, 'neg': 0}\n",
        "labels_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_pipeline = lambda x: labels_dict[x]"
      ],
      "metadata": {
        "id": "37ABEzkqqDPu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrained vectors\n",
        "In the following code cell we are going to download the predtrained word vectors. We are going to use the `GloVe.6B.100d`. These are pretrained vectors that were trained with about `~6B` words and have a vector representation of a word in `100` dimension. If you want to see which other vectors you can use in torchtext you can check [pytorch.org](https://pytorch.org/text/stable/vocab.html#glove). We are going to load these vectors as follows:"
      ],
      "metadata": {
        "id": "gZKJ8TFi5PkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_DIM = 100\n",
        "\n",
        "glove_vectors = vocab.GloVe('6B', dim=EMBEDDING_DIM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFa_AsjP5dXA",
        "outputId": "bd83b3e8-9ce3-406e-9847-9967f221b7a8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:42, 5.32MB/s]                           \n",
            "100%|█████████▉| 399999/400000 [00:16<00:00, 24672.97it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Embedding matrix\n",
        "Now that we have our glove vectors we need to costomize them so that they fit our use case. We are going to create an embedding matrix that suits the our vocabulary. So essentially this embedding matrix will be the word to vector mapping for all the words that arein our vocabulary."
      ],
      "metadata": {
        "id": "Eq9Pt8Cj5jBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = len(stoi)\n",
        "\n",
        "EMBEDDING_MATRIX= torch.zeros([VOCAB_SIZE, EMBEDDING_DIM])\n",
        "\n",
        "for i, word in enumerate(vocabulary.get_itos()):\n",
        "  EMBEDDING_MATRIX[i] = glove_vectors[word]"
      ],
      "metadata": {
        "id": "1nT113xaIHG3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the followig code cell we are going to check the embedding matrix for the word `good`."
      ],
      "metadata": {
        "id": "knttAuUb51PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_MATRIX[stoi['good']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn3ZvSbF54gY",
        "outputId": "c20d3419-90b2-4952-b7a2-c366d1c2cd9a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0308,  0.1199,  0.5391, -0.4370, -0.7394, -0.1534,  0.0811, -0.3856,\n",
              "        -0.6880, -0.4163, -0.1318, -0.2492,  0.4410,  0.0859,  0.2087, -0.0636,\n",
              "         0.0622, -0.0512, -0.1340,  1.1418,  0.0365,  0.4903, -0.2457, -0.4120,\n",
              "         0.1235,  0.4134, -0.4840, -0.5424, -0.2779, -0.2601, -0.3848,  0.7866,\n",
              "         0.1023, -0.2071,  0.4075,  0.3203, -0.5105,  0.4836, -0.0099, -0.3868,\n",
              "         0.0350, -0.1670,  0.4237, -0.5416, -0.3032, -0.3698,  0.0828, -0.5254,\n",
              "        -0.0645, -1.3980, -0.1487, -0.3533, -0.1118,  1.0912,  0.0959, -2.8129,\n",
              "         0.4524,  0.4621,  1.6012, -0.2084, -0.2738,  0.7120, -1.0754, -0.0470,\n",
              "         0.6748, -0.0658,  0.7582,  0.3941,  0.1551, -0.6472,  0.3280, -0.0317,\n",
              "         0.5290, -0.4389,  0.6740,  0.4214, -0.1198, -0.2178, -0.2976, -0.1351,\n",
              "         0.5990,  0.4653, -0.5826, -0.0232, -1.5442,  0.0190, -0.0159,  0.0245,\n",
              "        -0.5802, -0.6766, -0.0404, -0.4404,  0.0833,  0.2004, -0.7550,  0.1692,\n",
              "        -0.2657, -0.5288,  0.1758,  1.0650])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating the IMDBDataset\n",
        "In the following code cell we are going to create a dataset class called `IMDBDataset`. This dataset will takes in the `labels` and the `text` of a set."
      ],
      "metadata": {
        "id": "gtlx7nB5t8GO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "oJ4Dmh1Wtn2v"
      },
      "outputs": [],
      "source": [
        "class IMDBDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, labels, text):\n",
        "    super(IMDBDataset, self).__init__()\n",
        "    self.labels = labels\n",
        "    self.text = text\n",
        "      \n",
        "  def __getitem__(self, index):\n",
        "    return self.labels[index], self.text[index]\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### collate_fn\n",
        "We are going to create a collate function called `tokenize_batch`. This function acually takes in a batch and does the preprocessing of the text and labels. This function will be passed to the `DataLoader` class to do the preprocessing of features and labels.\n",
        "\n",
        "`tokenize_batch` function:\n",
        "\n",
        "* this function takes in a batch in each set and convert the features and labels to integer representation. It goes ahead and pad and truncate the sequence to the same length and returns `labels` and `features`."
      ],
      "metadata": {
        "id": "-CZwJvRnuSwV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "wC1WvA6o0wHB"
      },
      "outputs": [],
      "source": [
        "def tokenize_batch(batch, max_len=100, padding=\"pre\"):\n",
        "  assert padding==\"pre\" or padding==\"post\", \"the padding can be either pre or post\"\n",
        "  labels_list, text_list = [], []\n",
        "  for _label, _text in batch:\n",
        "    labels_list.append(label_pipeline(_label))\n",
        "    text_holder = torch.zeros(max_len, dtype=torch.int32)\n",
        "    processed_text = torch.tensor(text_pipeline(_text.lower()), dtype=torch.int32)\n",
        "    pos = min(max_len, len(processed_text))\n",
        "    if padding == \"pre\":\n",
        "      text_holder[:pos] = processed_text[:pos]\n",
        "    else:\n",
        "      text_holder[-pos:] = processed_text[-pos:]\n",
        "    text_list.append(text_holder.unsqueeze(dim=0))\n",
        "  return torch.FloatTensor(labels_list), torch.cat(text_list, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Datasets\n",
        "In the following code cell we are going to create the datasets for all our three sets using the `EmotionDataset` class."
      ],
      "metadata": {
        "id": "UpaPkrFavqES"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Ax5OE5WA0v1B"
      },
      "outputs": [],
      "source": [
        "train_dataset = IMDBDataset(train_labels, train_text)\n",
        "test_dataset = IMDBDataset(test_labels, test_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterators\n",
        "In the following code cell we are going to create loaders using the `DataLoader` class from `torch.utils.data` for our `3` sets. We are going to use the `batch_size` of `128` and our `collate_function` is `tokenize_batch`. For the validation and testing dataset we are going to set the shuffle to `False` because there's no need fo us to shuffle these examples."
      ],
      "metadata": {
        "id": "kNxTDNWFv4ip"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "hrCuNOQ60vyJ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 128\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=tokenize_batch)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=tokenize_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking a single Batch Data"
      ],
      "metadata": {
        "id": "jF2p2Ghrwq1Z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "AjdL94411cmC"
      },
      "outputs": [],
      "source": [
        "lbl, txt = iter(train_loader).next()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labels in the first batch."
      ],
      "metadata": {
        "id": "B4cTAtJWw5Ej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaJ0boJV1ci4",
        "outputId": "0df64665-c54e-4fc4-c764-a1148b5e2d0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
              "        0., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0.,\n",
              "        1., 0., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 0., 0., 0.,\n",
              "        0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.,\n",
              "        0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.,\n",
              "        1., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "lbl"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first sentence in the batch."
      ],
      "metadata": {
        "id": "nZIXj65Nw0o7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I1zg2W21cfn",
        "outputId": "140d8c35-6598-4bed-b4a8-acd43be95ae9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  137,    38,   690,    18,  1484,    13,    38,  1868,    22,    10,\n",
              "         3131,   126,    45,    38,  1484,    22,   152,  3436,   920,   405,\n",
              "           65,    85,  1938,    38,  1261,   479,     7,   520,  1771,    25,\n",
              "           70,     5,   453,   106,   314,   506,     7,    38,  6500,    85,\n",
              "           69,   919,    13,   431,  1261,   766,   283,   116, 10158,   287,\n",
              "           45,    38, 13902, 16827,     0,  3436,  1785,    25,    70,  1652,\n",
              "          419,    10,    85,   116,    48,    10,  7126, 13117,  2167,   284,\n",
              "           10,   280,    25,    54,   901,    42,   407,    65,   284,    10,\n",
              "          552,   624,    70,   419,    92,   931, 15063,   468,   159,   405,\n",
              "           97,    70,   126,  4710,   213,   567,   504,    10,  2277,    57],\n",
              "       dtype=torch.int32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "txt[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Creation\n",
        "\n",
        "Now that we have our loaders we can now create a model. The model that we are going to create is called `IMDBModel`. In the following code cell we are going to create our `CNN` model. Note that this code for creating a model was taken from [this notebook](https://github.com/CrispenGari/pytorch-python/blob/main/09_NLP/02_Sentiment_Analyisis_Series/04_CNN_Sentiment_Analyisis.ipynb). We are just going to modify it a little bit."
      ],
      "metadata": {
        "id": "YKJO5kzmw-Zk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "KY9NEb2X3XHV"
      },
      "outputs": [],
      "source": [
        "class IMDBModel(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "            dropout, pad_idx):\n",
        "    super(IMDBModel, self).__init__()\n",
        "    self.embedding = nn.Sequential(\n",
        "        nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_idx)\n",
        "    )\n",
        "    self.convs = nn.Sequential(\n",
        "        nn.ModuleList([\n",
        "            nn.Conv1d(\n",
        "                in_channels = embedding_dim, \n",
        "                out_channels = n_filters, \n",
        "                kernel_size = fs\n",
        "              ) for fs in filter_sizes\n",
        "        ])\n",
        "    )\n",
        "    self.out = nn.Sequential(\n",
        "        nn.Linear(len(filter_sizes) * n_filters, output_dim)\n",
        "    )\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "  def forward(self, text):\n",
        "    embedded = self.embedding(text)  \n",
        "    embedded = embedded.permute(0, 2, 1)\n",
        "    conved = [F.relu(conv(embedded)) for conv in self.convs[0]]\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n",
        "    cat = self.dropout(torch.cat(pooled, dim = 1))\n",
        "    return self.out(cat)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Instance\n",
        "\n",
        "In the following code cell we are going to create a model instance."
      ],
      "metadata": {
        "id": "QOTBZyfyyo9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cOl7yOQ3qp_",
        "outputId": "9a3b5ebb-3b4e-4a4e-a2bd-9e613456effb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IMDBModel(\n",
              "  (embedding): Sequential(\n",
              "    (0): Embedding(31264, 100, padding_idx=3)\n",
              "  )\n",
              "  (convs): Sequential(\n",
              "    (0): ModuleList(\n",
              "      (0): Conv1d(100, 100, kernel_size=(3,), stride=(1,))\n",
              "      (1): Conv1d(100, 100, kernel_size=(4,), stride=(1,))\n",
              "      (2): Conv1d(100, 100, kernel_size=(5,), stride=(1,))\n",
              "    )\n",
              "  )\n",
              "  (out): Sequential(\n",
              "    (0): Linear(in_features=300, out_features=1, bias=True)\n",
              "  )\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "INPUT_DIM = len(stoi) \n",
        "EMBEDDING_DIM = 100\n",
        "OUTPUT_DIM = 1\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = stoi['<pad>'] \n",
        "N_FILTERS = 100\n",
        "FILTER_SIZES = [3, 4, 5]\n",
        "\n",
        "imdb_model = IMDBModel(\n",
        " INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX\n",
        ").to(device)\n",
        "imdb_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Counting Model Parameters\n",
        "In the following code cell we are going to count the model parameters."
      ],
      "metadata": {
        "id": "-ZFVO2Sby_Nl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohLIvkfp4G_-",
        "outputId": "e3670a2a-6976-4eec-9bee-cd2d4c1a1e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of paramaters: 3,247,001\n",
            "Total tainable parameters: 3,247,001\n"
          ]
        }
      ],
      "source": [
        "def count_trainable_params(model):\n",
        "  return sum(p.numel() for p in model.parameters()), sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "n_params, trainable_params = count_trainable_params(imdb_model)\n",
        "print(f\"Total number of paramaters: {n_params:,}\\nTotal tainable parameters: {trainable_params:,}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Embedding Vectors\n",
        "\n",
        "In the following code cell we are going to load the pretained custom vectors in our embedding layer. We are going to load the embedding vectors tha suits our data using the `emotions_model.embedding[0].weight.data.copy_(EMBEDDING_MATRIX)` as follows:"
      ],
      "metadata": {
        "id": "Kx19zBrfJWaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_model.embedding[0].weight.data.copy_(EMBEDDING_MATRIX)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5qypqVNKEmL",
        "outputId": "235fb4cc-34cf-4075-f7b6-a61a0e2da40d"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        ...,\n",
              "        [ 0.5205,  0.0264, -0.5739,  ...,  0.4433, -0.4550, -0.0435],\n",
              "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "        [ 0.1073, -0.3334, -0.8606,  ...,  0.5667,  0.4736,  0.1538]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer and Criterion\n",
        "\n",
        "In the following code cell we are going to define the optimizer and criterion. For the optimizer we are going to use the `Adam` optimizer with default parameters and for the criterion we are going to use the `BCEWithLogitsLoss()` function since this is a binary classification task."
      ],
      "metadata": {
        "id": "El_Hir4a0G1K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "1rDO8fLM4ZeJ"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(imdb_model.parameters())\n",
        "criterion = nn.BCEWithLogitsLoss().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code cell we are going to create our `categorical_accuracy` function, which is a function that calulates the the catecorical accuracy between the predicted labels and real labels."
      ],
      "metadata": {
        "id": "gdGav6ES0nyk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "wSihiwCT4Za_"
      },
      "outputs": [],
      "source": [
        "def binary_accuracy(y_preds, y_true):\n",
        "  rounded_preds = torch.round(torch.sigmoid(y_preds))\n",
        "  correct = (rounded_preds == y_true).float() #convert into float for division \n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train and Evaluate functions\n",
        "\n",
        "In the following code cell we are going to create our `train` and `evalutate` functions:"
      ],
      "metadata": {
        "id": "oTlBUEOc0_vj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "gM7MoHZT4ZYP"
      },
      "outputs": [],
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "  epoch_loss,epoch_acc = 0, 0\n",
        "  model.train()\n",
        "  for batch in iterator:\n",
        "    y, X = batch\n",
        "    X = X.to(device)\n",
        "    y = y.to(device)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    predictions = model(X).squeeze(1)\n",
        "    loss = criterion(predictions, y)\n",
        "    acc = binary_accuracy(predictions, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def evaluate(model, iterator, criterion):\n",
        "  epoch_loss,epoch_acc = 0, 0\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch in iterator:\n",
        "      y, X = batch\n",
        "      X = X.to(device)\n",
        "      y = y.to(device)\n",
        "      predictions = model(X).squeeze(1)\n",
        "      loss = criterion(predictions, y)\n",
        "      acc = binary_accuracy(predictions, y)\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Loop\n",
        "\n",
        "In the following code cell we are going to run the training loop. We are going to save the model when the loss decreased."
      ],
      "metadata": {
        "id": "RF-JtqA_2TNL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk8kgNg35Mqg",
        "outputId": "4d13081c-2445-479b-af28-0a30c7f0c98a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------------+\n",
            "|     EPOCH: 01/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.563 |    0.701 | 0:00:37.10 |\n",
            "| Validation | 0.450 |    0.789 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 02/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.405 |    0.818 | 0:00:32.21 |\n",
            "| Validation | 0.411 |    0.808 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|     EPOCH: 03/10 saving best model...      |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.318 |    0.866 | 0:00:32.85 |\n",
            "| Validation | 0.399 |    0.818 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 04/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.236 |    0.908 | 0:00:34.57 |\n",
            "| Validation | 0.428 |    0.812 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 05/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.163 |    0.941 | 0:00:35.74 |\n",
            "| Validation | 0.484 |    0.803 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 06/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.105 |    0.965 | 0:00:32.83 |\n",
            "| Validation | 0.548 |    0.798 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 07/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.069 |    0.978 | 0:00:34.03 |\n",
            "| Validation | 0.632 |    0.794 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 08/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.040 |    0.990 | 0:00:34.48 |\n",
            "| Validation | 0.716 |    0.792 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 09/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.027 |    0.993 | 0:00:30.31 |\n",
            "| Validation | 0.787 |    0.787 |            |\n",
            "+------------+-------+----------+------------+\n",
            "+--------------------------------------------+\n",
            "|         EPOCH: 10/10 not saving...         |\n",
            "+------------+-------+----------+------------+\n",
            "|  CATEGORY  |  LOSS | ACCURACY |    ETA     |\n",
            "+------------+-------+----------+------------+\n",
            "| Training   | 0.019 |    0.995 | 0:00:31.41 |\n",
            "| Validation | 0.863 |    0.786 |            |\n",
            "+------------+-------+----------+------------+\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 10\n",
        "MODEL_NAME = 'imdb-torch.pt'\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "for epoch in range(N_EPOCHS):\n",
        "  start = time.time()\n",
        "  train_loss, train_acc = train(imdb_model, train_loader, optimizer, criterion)\n",
        "  valid_loss, valid_acc = evaluate(imdb_model, test_loader, criterion)\n",
        "  title = f\"EPOCH: {epoch+1:02}/{N_EPOCHS:02} {'saving best model...' if valid_loss < best_valid_loss else 'not saving...'}\"\n",
        "  if valid_loss < best_valid_loss:\n",
        "      best_valid_loss = valid_loss\n",
        "      torch.save(imdb_model.state_dict(), MODEL_NAME)\n",
        "  end = time.time()\n",
        "  data = [\n",
        "       [\"Training\", f'{train_loss:.3f}', f'{train_acc:.3f}', f\"{utils.hms_string(end - start)}\" ],\n",
        "       [\"Validation\", f'{valid_loss:.3f}', f'{valid_acc:.3f}', \"\" ],       \n",
        "   ]\n",
        "  columns = [\"CATEGORY\", \"LOSS\", \"ACCURACY\", \"ETA\"]\n",
        "  tables.tabulate_data(columns, data, title)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the best model.\n",
        "In the following code cell we are going to evaluate the best model using on the `test` data as follows:"
      ],
      "metadata": {
        "id": "HNwUpIZ92-6h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkwGMhww5tXH",
        "outputId": "bb2f2efc-0805-47f2-a351-96f7fdfb3a26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------------+\n",
            "|       Model Evaluation Summary       |\n",
            "+------+-------+----------+------------+\n",
            "| Set  |  Loss | Accuracy | ETA (time) |\n",
            "+------+-------+----------+------------+\n",
            "| Test | 0.399 |   81.84% |            |\n",
            "+------+-------+----------+------------+\n"
          ]
        }
      ],
      "source": [
        "column_names = [\"Set\", \"Loss\", \"Accuracy\", \"ETA (time)\"]\n",
        "imdb_model.load_state_dict(torch.load(MODEL_NAME))\n",
        "test_loss, test_acc = evaluate(imdb_model, test_loader, criterion)\n",
        "title = \"Model Evaluation Summary\"\n",
        "data_rows = [[\"Test\", f'{test_loss:.3f}', f'{test_acc * 100:.2f}%', \"\"]]\n",
        "\n",
        "tables.tabulate_data(column_names, data_rows, title)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference\n",
        "In the following code cell we are going to make predictions with the best model. We will have the function called `inference_preprocess_text` which is a function that process the text for inference."
      ],
      "metadata": {
        "id": "gRAWjwfd3XZg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "maLH9sSM8HfT"
      },
      "outputs": [],
      "source": [
        "def inference_preprocess_text(text, max_len=100, padding=\"pre\"):\n",
        "  assert padding==\"pre\" or padding==\"post\", \"the padding can be either pre or post\"\n",
        "  text_holder = torch.zeros(max_len, dtype=torch.int32) # fixed size tensor of max_len with <pad> = 0\n",
        "  processed_text = torch.tensor(text_pipeline(text), dtype=torch.int32)\n",
        "  pos = min(max_len, len(processed_text))\n",
        "  if padding == \"pre\":\n",
        "    text_holder[:pos] = processed_text[:pos]\n",
        "  else:\n",
        "    text_holder[-pos:] = processed_text[-pos:]\n",
        "  text_list= text_holder.unsqueeze(dim=0)\n",
        "  return text_list"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Inference\n",
        "In the following code cell we are going to create a function that predicts the movie review sentiment in the text that is called `predict_sentiment`."
      ],
      "metadata": {
        "id": "_OIlVvSs318q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "yFSdomq15tUC"
      },
      "outputs": [],
      "source": [
        "def predict_sentiment(model, sentence, min_len = 5):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    tensor = inference_preprocess_text(sentence).to(device)\n",
        "    probability= torch.sigmoid(model(tensor).squeeze(0)).detach().cpu().item()\n",
        "    prediction = round(probability)\n",
        "    probability = probability if prediction == 1 else 1 - probability\n",
        "    classes = {v:k for k, v in labels_dict.items()}\n",
        "    class_name = classes[prediction]\n",
        "    columns_ =  [\"label\", 'value']\n",
        "    title = \"PREDICTIONS OF EMOTIONS\"\n",
        "    data = [\n",
        "        ['text', sentence],\n",
        "        ['predicted class', prediction],\n",
        "        ['predicted class name', class_name],\n",
        "        ['probability', round(probability, 2)]\n",
        "    ]\n",
        "    tables.tabulate_data(columns_, data, title)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# negative review\n",
        "predict_sentiment(imdb_model, \"this movie is boring i don't like it at all.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVpBH0sB5Cc4",
        "outputId": "cd74e1db-17b4-49e3-f086-babe5f799646"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------------------------------------------------------+\n",
            "|                       PREDICTIONS OF EMOTIONS                       |\n",
            "+----------------------+----------------------------------------------+\n",
            "|        label         |                    value                     |\n",
            "+----------------------+----------------------------------------------+\n",
            "| text                 | this movie is boring i don't like it at all. |\n",
            "| predicted class      |                                            0 |\n",
            "| predicted class name |                                          neg |\n",
            "| probability          |                                         0.95 |\n",
            "+----------------------+----------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5Oe97TB5tQz",
        "outputId": "6bccedfb-c152-42fe-caf4-9be4c452188c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------------------+\n",
            "|              PREDICTIONS OF EMOTIONS               |\n",
            "+----------------------+-----------------------------+\n",
            "|        label         |            value            |\n",
            "+----------------------+-----------------------------+\n",
            "| text                 | the best movie of all time. |\n",
            "| predicted class      |                           1 |\n",
            "| predicted class name |                         pos |\n",
            "| probability          |                        0.89 |\n",
            "+----------------------+-----------------------------+\n"
          ]
        }
      ],
      "source": [
        "# fear\n",
        "predict_sentiment(imdb_model, \"the best movie of all time.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion matrix.\n",
        "\n",
        "In the following code cell we are going to extract features and labels that we are going to use to plot our confusion matrix. We are going to use the `test` set."
      ],
      "metadata": {
        "id": "r-rTezKO8eSK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "b8STMjVSBOOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8418f5e3-1fd4-4a70-d3c6-bf5d640a0693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "test_features = []\n",
        "test_labels = []\n",
        "for (y, X) in test_loader:\n",
        "  test_features.extend(X.numpy())\n",
        "  test_labels.extend(y.numpy())\n",
        "test_features = torch.tensor([i for i in test_features]).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "imdb_model.eval()\n",
        "with torch.no_grad():\n",
        "  preds = torch.sigmoid(imdb_model(test_features))\n",
        "  preds = [1 if pred >=0.5 else 0 for pred in preds]"
      ],
      "metadata": {
        "id": "jNXRZ38O9dOA"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [k for k, v in labels_dict.items()]\n",
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Rpz5MNFAeee",
        "outputId": "c1d03517-54c1-4f27-a2d5-badfaf64c260"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['pos', 'neg']"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualization.plot_complicated_confusion_matrix(test_labels, preds, classes, figsize=(10, 10), fontsize=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "id": "FF9xdUGO-xQV",
        "outputId": "3cac5440-6f75-4949-e8ce-27db39dc368f"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EkQgTAR6KIdg"
      },
      "execution_count": 51,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "06_TORCHTEXT_CNN_BINARY_CLASSIFICATION.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}